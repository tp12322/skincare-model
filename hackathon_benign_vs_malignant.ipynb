{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CSW0DFwinTEG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_DjqKKSSuqJS"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhSGxtSBpyoI",
        "outputId": "422470e6-4321-4ac9-9c00-d95f407c6edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "train_path = '/content/drive/MyDrive/sampledata/Train/ '\n",
        "test_path = '/content/drive/MyDrive/sampledata/Test/ '\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUVTYKtov2nZ",
        "outputId": "3efca0d0-8333-4c0e-da90-198609054b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 853 images belonging to 2 classes.\n",
            "Found 118 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 89s 3s/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 8.7594 - val_accuracy: 0.8661\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 75s 2s/step - loss: 9.5461e-14 - accuracy: 1.0000 - val_loss: 9.9064 - val_accuracy: 0.8571\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 79s 3s/step - loss: 7.4670e-13 - accuracy: 1.0000 - val_loss: 9.9283 - val_accuracy: 0.8571\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 79s 3s/step - loss: 2.6740e-12 - accuracy: 1.0000 - val_loss: 9.2821 - val_accuracy: 0.8661\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 79s 3s/step - loss: 8.9520e-13 - accuracy: 1.0000 - val_loss: 9.3163 - val_accuracy: 0.8661\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the paths to your dataset\n",
        "train_data_dir = '/content/drive/MyDrive/sampledata/Train'\n",
        "test_data_dir = '/content/drive/MyDrive/sampledata/Test'\n",
        "\n",
        "# Set the image dimensions and batch size\n",
        "img_width, img_height = 64, 64\n",
        "batch_size = 28\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers for mole classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     test_data_dir,\n",
        "#     target_size=(img_width, img_height),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='binary',\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# prediction_of_y = model.predict(test_generator)\n",
        "# prediction_of_y = (prediction_of_y > 0.5).astype(int)\n",
        "# class_labels = list(test_generator.class_indices.keys())\n",
        "# report = classification_report(test_generator.classes, prediction_of_y, target_names=class_labels)\n",
        "# print(report)\n",
        "checkpoint_path = \".\"\n",
        "model.save_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP4B4Wuszq0u",
        "outputId": "a1d3a64d-a55c-479d-f8cb-0a715e8b9ac1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/contents/checkpoint1.ckpt\")"
      ],
      "metadata": {
        "id": "aJNCwPSUDAxk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/contents/checkpoint1.ckpt\")\n",
        "import cv2\n",
        "# Define the paths to your dataset\n",
        "train_data_dir = '/content/drive/MyDrive/sampledata/Train'\n",
        "test_data_dir = '/content/drive/MyDrive/sampledata/Test'\n",
        "\n",
        "# Set the image dimensions and batch size\n",
        "img_width, img_height = 64, 64\n",
        "batch_size = 28\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=None,\n",
        "    shear_range=0.0,\n",
        "    zoom_range=0.0,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "prediction_of_y = model.predict(test_generator)\n",
        "prediction_of_y = (prediction_of_y > 0.5).astype(int)\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "report = classification_report(test_generator.classes, prediction_of_y, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(validation_generator, verbose=0)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLQEanfxDqoS",
        "outputId": "e3fada40-f0e0-42e4-d3eb-6c4bc46ce25a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 853 images belonging to 2 classes.\n",
            "Found 118 images belonging to 2 classes.\n",
            "Found 118 images belonging to 2 classes.\n",
            "5/5 [==============================] - 16s 3s/step\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                not benign       0.86      1.00      0.93       102\n",
            "pigmented benign keratosis       0.00      0.00      0.00        16\n",
            "\n",
            "                  accuracy                           0.86       118\n",
            "                 macro avg       0.43      0.50      0.46       118\n",
            "              weighted avg       0.75      0.86      0.80       118\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored model, accuracy: 86.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "DaAGdeuJGbzh",
        "outputId": "7556aa1f-9a54-483c-cee9-5ccc5a8b7a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 118 images belonging to 2 classes.\n",
            "Found 853 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6ad88ac84283>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Load the training and testing data\n",
        "train_data = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_dataset = train_data.flow_from_directory(\n",
        "    '/content/drive/MyDrive/sampledata/Test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_data = ImageDataGenerator(rescale=1./255)\n",
        "test_dataset = test_data.flow_from_directory(\n",
        "    '/content/drive/MyDrive/sampledata/Train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_dataset, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_dataset)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_dataset)\n",
        "\n",
        "# Print the predictions\n",
        "for i in range(len(predictions)):\n",
        "    print('Prediction:', predictions[i], 'Actual:', test_dataset.classes[i])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}